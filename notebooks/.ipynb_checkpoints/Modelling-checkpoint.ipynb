{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc0af4c-ddf6-4729-8cea-952f3c7d1104",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install optuna pandas scikit-learn scikit-optimize statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88537431-7a90-4c7c-a1d0-5eeb475c641e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from include.graficos import *\n",
    "from include.utils import *\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import optuna\n",
    "import os\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f178e3-93ea-45ca-8c37-9aeb74ea7184",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from skopt import BayesSearchCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.linear_model import Lasso, LinearRegression, Ridge\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320499db-f973-450a-9aab-316e6426be3a",
   "metadata": {},
   "source": [
    "**1. Engenharia de Recursos**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a110e58-c228-4985-a256-24ffc5dcc631",
   "metadata": {},
   "source": [
    "Nesta seção, é carregado os dados processados de arquivos CSV, convertido rótulos em arrays unidimensionais e também são removidas colunas específicas dos DataFrames de treino e teste para futuras operações de modelagem ou análise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b10de9-2b41-4f53-b88d-2d46be3eb795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtém a largura do terminal - uso mais embaixo nos prints\n",
    "terminal_width = os.get_terminal_size().columns\n",
    "\n",
    "# Carregando os dados processados\n",
    "dados_originais = pd.read_csv('../planilhas/1_dados_sinteticos.csv', encoding='latin-1')\n",
    "X_train = pd.read_csv('../planilhas/2_dados_processados_treino.csv', encoding='latin-1')\n",
    "X_test = pd.read_csv('../planilhas/3_dados_processados_teste.csv', encoding='latin-1')\n",
    "y_train = pd.read_csv('../planilhas/4_dados_processados_treino_target.csv', encoding='latin-1')\n",
    "y_test = pd.read_csv('../planilhas/5_dados_processados_teste_target.csv', encoding='latin-1')\n",
    "\n",
    "# Convertendo y_train em um array unidimensional\n",
    "y_train = y_train.values.ravel()\n",
    "\n",
    "# Convertendo y_test em um array unidimensional\n",
    "y_test = y_test.values.ravel()\n",
    "\n",
    "# Descartando na predição do modelo, mas trago novamente nos dados futuros\n",
    "colunas_descartadas_treino = X_train[['Gênero','Região','Categoria_IMC']]\n",
    "colunas_descartadas_teste = X_test[['Gênero','Região','Categoria_IMC']]\n",
    "X_train = X_train.drop(colunas_descartadas_treino, axis=1)\n",
    "X_test = X_test.drop(colunas_descartadas_teste, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad26fe86-4dd4-488f-90ee-3a86ac237459",
   "metadata": {},
   "source": [
    "**2. Pré-processamento**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aefcadca-0307-4ddb-9155-678eaa482077",
   "metadata": {},
   "source": [
    "Nesta seção, inicializamos um StandardScaler para padronizar os dados de treinamento (X_train) e teste (X_test).\n",
    "\n",
    "Após aplicar a padronização, é calculada uma matriz de correlação entre as colunas numéricas de X_train e visualizada por meio de um mapa de calor. A análise mostra que não há relacionamentos significativos entre as features, com exceção da correlação entre o alvo (target) e algumas features, conforme identificado na análise exploratória dos dados (EDA)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17d1075-c010-4b2d-bb6a-1f63dc89cd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializando o StandardScaler, que é usado para padronizar os recursos\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Aplicando a transformação de padronização nos dados de treinamento e ajustar o scaler aos dados\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Aplicando a mesma transformação de padronização aos dados de teste\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a2f6c4-519c-41f0-9e80-6b1577fedfa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns = X_train.select_dtypes(include='number')\n",
    "\n",
    "print(\"\\nCalculando a matriz de correlação entre os dados de treinamento:\")\n",
    "correlation_matrix = numeric_columns.corr().round(2)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20,20))\n",
    "sns.heatmap(data=correlation_matrix, annot=True, linewidths=.5, ax=ax, cmap=\"coolwarm\")\n",
    "\n",
    "print(\"\\nFoi detectado que não existe relacionamento válido a ser considerado entre as features.\")\n",
    "print(\"\\nA única correlação válida é entre o target e algumas features, conforme visto no EDA.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97c5862-6ad0-4e20-9e49-a447bfaa48c2",
   "metadata": {},
   "source": [
    "**3. Treinamento do Modelo**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7172906c-b70c-49b6-81ca-ec3497f51c9d",
   "metadata": {},
   "source": [
    "Nesta seção, treinamos e avaliamos modelos de aprendizado de máquina com otimização de hiperparâmetros usando BayesSearchCV.\n",
    "Além disso, calculamos métricas de desempenho dos modelos, e exibimos a importância das características para modelos com suporte a essa funcionalidade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2204d8a0-b97e-4ce2-a905-78ff8791deab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adicionando mais modelos ao dicionário de modelos\n",
    "models = {\n",
    "    'Random Forest Regressor': RandomForestRegressor(),\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Support Vector Regression': SVR(),\n",
    "    'Decision Tree Regressor': DecisionTreeRegressor(),\n",
    "    'K-Nearest Neighbors Regressor': KNeighborsRegressor(),\n",
    "    'Gradient Boosting Regressor': GradientBoostingRegressor(),\n",
    "    'Lasso Regression': Lasso(),\n",
    "    'Ridge Regression': Ridge()\n",
    "}\n",
    "\n",
    "param_spaces = {\n",
    "    'Random Forest Regressor': {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': list(range(1, 11)),\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4],\n",
    "        'max_features': ['sqrt', 'log2', None]\n",
    "    },\n",
    "    'Support Vector Regression': {\n",
    "        'C': [0.1, 1, 10],\n",
    "        'gamma': ['scale', 'auto'],\n",
    "        'kernel': ['linear']\n",
    "    },\n",
    "    'Decision Tree Regressor': {\n",
    "        'max_depth': list(range(1, 11)),\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4],\n",
    "        'max_features': ['sqrt', 'log2', None]\n",
    "    },\n",
    "    'K-Nearest Neighbors Regressor': {\n",
    "        'n_neighbors': list(range(3, 11)),\n",
    "        'weights': ['uniform', 'distance']\n",
    "    },\n",
    "    'Gradient Boosting Regressor': {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': list(range(1, 11)),\n",
    "        'learning_rate': [0.05, 0.1, 0.2]\n",
    "    },\n",
    "    'Lasso Regression': {\n",
    "        'alpha': [0.1, 1, 10],\n",
    "        'selection': ['cyclic', 'random']\n",
    "    },\n",
    "    'Linear Regression': {\n",
    "        'fit_intercept': [True, False],\n",
    "        'copy_X': [True, False],\n",
    "        'n_jobs': [-1]  # Se quiser paralelizar o processo de ajuste\n",
    "    },\n",
    "    'Ridge Regression': {\n",
    "        'alpha': [0.1, 1, 10],\n",
    "        'fit_intercept': [True, False],\n",
    "        'solver': ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga']\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be67531c-1538-4d5e-858f-7ab5406ffd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Número de interações usado no método abaixo BayesSearchCV (como demora um pouco, caso seja necessário, basta reduzir a quantidade de interações)\n",
    "numero_interacoes_bayes_search = 3\n",
    "\n",
    "# Criação de variável kfold, com definição de volume de treinamentos e com embaralhamento dos dados\n",
    "kfold = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "# Utilizamos BayesSearchCV pois nos estudos feitos vimos que se trata de uma ferramenta de otimização de hiperparâmetros\n",
    "# usada em aprendizado de máquina para encontrar a melhor combinação de hiperparâmetros para um modelo dado\n",
    "\n",
    "# Chegamos a realizar estudos com GridSearchCV e RandomizedSearchCV, e obtivemos melhores resultados no BayesSearchCV\n",
    "\n",
    "# Treinamento e avaliação dos modelos com BayesSearchCV\n",
    "for name, model in models.items():\n",
    "    # Imprime uma linha separadora com base na largura do terminal\n",
    "    print('-' * terminal_width)\n",
    "    print(f\"Modelo {name}:\");\n",
    "    \n",
    "    try:\n",
    "        verificar_se_modelo_tem_dados_nan_inf(model, X_train_scaled, y_train)\n",
    "        print(f\"\\nSem NaN e Inf nas previsões do modelo\")\n",
    "    except ValueError as e:\n",
    "        print(f\"{name}: {e}\")\n",
    "    \n",
    "    if name in param_spaces:\n",
    "        # neg_mean_squared_error é uma métrica usada em problemas de aprendizado de máquina, especialmente em modelos de regressão\n",
    "        # para medir a diferença entre valores previstos e valores reais\n",
    "        bayes_search = BayesSearchCV(model, param_spaces[name], cv=5, scoring='neg_mean_squared_error', n_iter=numero_interacoes_bayes_search, random_state=42)\n",
    "        bayes_search.fit(X_train_scaled, y_train)\n",
    "        model = bayes_search.best_estimator_\n",
    "        print(f\"\\nMelhores parâmetros: {bayes_search.best_params_}\")\n",
    "    \n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r_quadrado = r2_score(y_test, y_pred)\n",
    "\n",
    "    # Calcular acurácia média usando validação cruzada\n",
    "    scores = cross_val_score(model, X_train_scaled, y_train, cv=kfold)\n",
    "\n",
    "    print(f'\\nErro Médio Quadrático (MSE): {round(mse,2)}')\n",
    "    print(f'\\nErro Absoluto Médio (MAE): {round(mae.mean(),2)}')\n",
    "    print(f'\\nCoeficiente de determinação (R2): {round(r_quadrado.mean(),2)}')\n",
    "    print(f'\\nAcurácia média com validação cruzada: {round(scores.mean(),2)}')\n",
    "        \n",
    "    # Calcula e exibe a importância das características para o modelo atual\n",
    "    if hasattr(model, 'feature_importances_'):\n",
    "        importance_df = pd.DataFrame({'Colunas': X_train.columns, 'Importância': model.feature_importances_})\n",
    "        importance_df = importance_df.sort_values(by='Importância', ascending=False)\n",
    "        print(f\"\\nImportância das características:\")\n",
    "        print(f'\\n{round(importance_df,2)}')\n",
    "    elif isinstance(model, LinearRegression) or isinstance(model, Lasso) or isinstance(model, Ridge):        \n",
    "        importance_df = pd.DataFrame({'Colunas': X_train.columns, 'Coeficiente': model.coef_})\n",
    "        importance_df = importance_df.sort_values(by='Coeficiente', ascending=False)\n",
    "        print(f\"\\nCoeficientes das características:\")\n",
    "        print(f'\\n{round(importance_df,2)}')\n",
    "    elif isinstance(model, SVR):\n",
    "        support_indices = model.support_\n",
    "        support_features = X_train.iloc[support_indices]\n",
    "        feature_importance_svr = support_features.mean(axis=0)\n",
    "        importance_df = pd.DataFrame({'Colunas': X_train.columns, 'Importância': feature_importance_svr})\n",
    "        importance_df = importance_df.sort_values(by='Importância', ascending=False)\n",
    "        print(f\"\\nImportância das características:\")\n",
    "        print(f'\\n{round(importance_df,2)}')\n",
    "    else:\n",
    "        print(\"\\nNão é possível calcular a importância das características\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48fb4ff9-f2ce-4114-bc95-28f313d6690f",
   "metadata": {},
   "source": [
    "**4. Comparação de Modelos**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c965aa0-512a-4e4b-a6e3-d9b56baf8170",
   "metadata": {},
   "source": [
    "Nesta seção, selecionamos o melhor modelo (best_model_name) com base na maior pontuação média de validação cruzada. Ele percorre um dicionário de modelos (models) e calcula a pontuação média de validação cruzada de cada modelo usando cross_val_score consumindo os parametros indicados na variável kfold, nos dados de treinamento padronizados (X_train_scaled) e nos rótulos de treinamento (y_train).\n",
    "\n",
    "O modelo com a maior pontuação média de validação cruzada é selecionado como o melhor modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955fbdea-faea-4285-8298-76b32a8bd648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleção de modelo com base na maior pontuação de validação cruzada\n",
    "best_model_name = max(models, key=lambda model: cross_val_score(models[model], X_train_scaled, y_train, cv=kfold).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9684717-7ac2-4c36-a697-1f3a72d85d51",
   "metadata": {},
   "source": [
    "**5. Seleção de Modelo**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121e2e78-c31f-49a8-b971-64fe4d5dee03",
   "metadata": {},
   "source": [
    "Nesta seção, selecionamos o melhor modelo (best_model) a partir de um dicionário de modelos (models) usando o nome do melhor modelo (best_model_name). Em seguida, imprimimos o nome do melhor modelo escolhido para fornecer informações sobre qual modelo será utilizado nas análises que seram feitas abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16947f1b-a506-4540-9068-99f278e9d558",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = models[best_model_name]\n",
    "print(f'Melhor modelo: {best_model_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2c235a-b688-4d6b-8820-de8a50e3e4a8",
   "metadata": {},
   "source": [
    "**6. Otimização de Modelo**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8726630e-26c9-4086-b420-532c483c5d5a",
   "metadata": {},
   "source": [
    "Nesta seção, utilizamos o Optuna para otimizar hiperparâmetros de modelos de aprendizado de máquina, ajustando-os para melhorar o desempenho, e exibimos métricas de avaliação como Erro Médio Quadrático (MSE), Erro Absoluto Médio (MAE) e coeficiente de determinação (R2).\n",
    "\n",
    "Também calculamos a importância das características para modelos com suporte a esse atributo, além de verificar a correlação entre as principais características e os custos médicos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36479d9-807c-4862-bcd6-a1b06426edce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escolhemos a biblioteca Optuna para otimização de hiperparâmetros no aprendizado de máquina\n",
    "# Trata-se de uma ferramenta poderosa que pode ser usada para ajustar automaticamente os hiperparâmetros de modelos para melhorar seu desempenho.\n",
    "# Utiliza técnicas de otimização, usamos inclusive a otimização bayesiana, para encontrar os melhores valores de hiperparâmetros de forma eficiente.\n",
    "\n",
    "# Caso seja necessário, basta aumentar as tentativas de estudo do optuna\n",
    "numero_tentativas_estudo_optuna = 10\n",
    "\n",
    "def create_model(trial):\n",
    "    if best_model_name == 'Random Forest Regressor':\n",
    "        n_estimators = trial.suggest_categorical('n_estimators', param_spaces[best_model_name]['n_estimators'])\n",
    "        max_depth = trial.suggest_categorical('max_depth', param_spaces[best_model_name]['max_depth'])\n",
    "        min_samples_split = trial.suggest_categorical('min_samples_split', param_spaces[best_model_name]['min_samples_split'])\n",
    "        min_samples_leaf = trial.suggest_categorical('min_samples_leaf', param_spaces[best_model_name]['min_samples_leaf'])\n",
    "        max_features = trial.suggest_categorical('max_features', param_spaces[best_model_name]['max_features'])\n",
    "        model = RandomForestRegressor(n_estimators=n_estimators, \n",
    "                                       max_depth=max_depth, \n",
    "                                       min_samples_split=min_samples_split,\n",
    "                                       min_samples_leaf=min_samples_leaf,\n",
    "                                       max_features=max_features)\n",
    "    elif best_model_name == 'Decision Tree Regressor':\n",
    "        max_depth = trial.suggest_categorical('max_depth', param_spaces[best_model_name]['max_depth'])\n",
    "        min_samples_split = trial.suggest_categorical('min_samples_split', param_spaces[best_model_name]['min_samples_split'])\n",
    "        min_samples_leaf = trial.suggest_categorical('min_samples_leaf', param_spaces[best_model_name]['min_samples_leaf'])\n",
    "        model = DecisionTreeRegressor(max_depth=max_depth,\n",
    "                                       min_samples_split=min_samples_split,\n",
    "                                       min_samples_leaf=min_samples_leaf)\n",
    "    elif best_model_name == 'Support Vector Regression':\n",
    "        C = trial.suggest_categorical('C', param_spaces[best_model_name]['C'])\n",
    "        gamma = trial.suggest_categorical('gamma', param_spaces[best_model_name]['gamma'])\n",
    "        kernel = trial.suggest_categorical('kernel', param_spaces[best_model_name]['kernel'])\n",
    "        model = SVR(C=C, gamma=gamma, kernel=kernel)\n",
    "    elif best_model_name == 'Linear Regression':\n",
    "        fit_intercept = trial.suggest_categorical('fit_intercept', param_spaces[best_model_name]['fit_intercept'])\n",
    "        copy_X = trial.suggest_categorical('copy_X', param_spaces[best_model_name]['copy_X'])\n",
    "        n_jobs = trial.suggest_categorical('n_jobs', param_spaces[best_model_name]['n_jobs'])\n",
    "        model = LinearRegression(fit_intercept=fit_intercept, copy_X=copy_X, n_jobs=n_jobs)\n",
    "    elif best_model_name == 'K-Nearest Neighbors Regressor':\n",
    "        n_neighbors = trial.suggest_categorical('n_neighbors', param_spaces[best_model_name]['n_neighbors'])\n",
    "        weights = trial.suggest_categorical('weights', param_spaces[best_model_name]['weights'])\n",
    "        model = KNeighborsRegressor(n_neighbors=n_neighbors, weights=weights)\n",
    "    elif best_model_name == 'Gradient Boosting Regressor':\n",
    "        n_estimators = trial.suggest_categorical('n_estimators', param_spaces[best_model_name]['n_estimators'])\n",
    "        max_depth = trial.suggest_categorical('max_depth', param_spaces[best_model_name]['max_depth'])\n",
    "        learning_rate = trial.suggest_categorical('learning_rate', param_spaces[best_model_name]['learning_rate'])\n",
    "        model = GradientBoostingRegressor(n_estimators=n_estimators, max_depth=max_depth, learning_rate=learning_rate)\n",
    "    elif best_model_name == 'Lasso Regression':\n",
    "        alpha = trial.suggest_categorical('alpha', param_spaces[best_model_name]['alpha'])\n",
    "        selection = trial.suggest_categorical('selection', param_spaces[best_model_name]['selection'])\n",
    "        model = Lasso(alpha=alpha, selection=selection)\n",
    "    elif best_model_name == 'Ridge Regression':\n",
    "        alpha = trial.suggest_float('alpha', param_spaces[best_model_name]['alpha'][0], param_spaces[best_model_name]['alpha'][-1])\n",
    "        fit_intercept = trial.suggest_categorical('fit_intercept', param_spaces[best_model_name]['fit_intercept'])\n",
    "        solver = trial.suggest_categorical('solver', param_spaces[best_model_name]['solver'])\n",
    "        model = Ridge(alpha=alpha, fit_intercept=fit_intercept, solver=solver)\n",
    "    else:\n",
    "        model = models[best_model_name]  # Usar os hiperparâmetros padrão para outros modelos\n",
    "    return model\n",
    "\n",
    "# Função para otimização de hiperparâmetros\n",
    "def objective(trial):\n",
    "    # Criar uma nova instância do modelo com hiperparâmetros definidos pelo Optuna\n",
    "    model = create_model(trial)\n",
    "    \n",
    "    # Avaliação do modelo utilizando validação cruzada\n",
    "    score = cross_val_score(model, X_train_scaled, y_train, n_jobs=-1, cv=kfold, scoring='neg_mean_squared_error').mean()\n",
    "    return score\n",
    "\n",
    "# Criar o objeto de estudo Optuna usando create_study()\n",
    "# Ciando um novo estudo de otimização, que é uma estrutura para gerenciar a busca de hiperparâmetros.\n",
    "# Usamos a direção maximize, tentando encontrar os valores dos hiperparâmetros que resultem na maior pontuação possível.\n",
    "study = optuna.create_study(direction='maximize')\n",
    "\n",
    "# Realizar a otimização dos hiperparâmetros\n",
    "study.optimize(objective, n_trials=numero_tentativas_estudo_optuna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c466152-7210-4ae6-bbe2-50bbd3fcd988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenha os melhores parâmetros do estudo Optuna\n",
    "best_params = study.best_params\n",
    "best_score = study.best_value\n",
    "\n",
    "# Configure o modelo com os melhores parâmetros\n",
    "best_model.set_params(**best_params)\n",
    "\n",
    "# Ajuste o modelo aos dados de treinamento com os melhores parâmetros\n",
    "best_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Avaliação do modelo após o ajuste com os melhores parâmetros\n",
    "score_train = best_model.score(X_train_scaled, y_train)\n",
    "score_test = best_model.score(X_test_scaled, y_test)\n",
    "\n",
    "y_pred = best_model.predict(X_test_scaled)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r_quadrado = r2_score(y_test, y_pred)\n",
    "\n",
    "# Imprimir resultados\n",
    "print(f\"\\nModelo:\", best_model_name)\n",
    "print(\"\\nMelhores parâmetros:\", best_params)\n",
    "print(\"\\nMelhor score:\", round(best_score,2))\n",
    "print(f\"\\nScore treino: {round(score_train,2)}\")\n",
    "print(f\"\\nScore teste: {round(score_test,2)}\")\n",
    "print(f'\\nErro Médio Quadrático (MSE): {round(mse,2)}')\n",
    "print(f'\\nErro Absoluto Médio (MAE): {round(mae.mean(),2)}')\n",
    "print(f'\\nCoeficiente de determinação (R2): {round(r_quadrado.mean(),2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33547ecc-41db-4611-b112-781aa8ad267f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obter a importância das características apenas para modelos que suportam esse atributo\n",
    "if hasattr(best_model, 'feature_importances_'):\n",
    "    # Obter a importância das características do modelo\n",
    "    feature_importances = best_model.feature_importances_\n",
    "    \n",
    "    # Criar um DataFrame para visualizar a importância das características\n",
    "    importance_df = pd.DataFrame({'Colunas': X_train.columns, 'Importância': feature_importances})\n",
    "\n",
    "    # Ordenar as características por importância\n",
    "    importance_df = importance_df.sort_values(by='Importância', ascending=False)\n",
    "    \n",
    "    print(\"\\nQuais características individuais têm maior impacto nos custos médicos cobrados pelo seguro de saúde?\")\n",
    "    print(round(importance_df,2))\n",
    "\n",
    "    # Selecionar as características mais importantes (por exemplo, as 10 mais importantes)\n",
    "    top_features = importance_df.head(10)['Colunas'].tolist()  # Ajuste o número conforme necessário\n",
    "    \n",
    "    # Calcular a matriz de correlação apenas para as características mais importantes\n",
    "    correlation_matrix = X_train[top_features].corr()\n",
    "    \n",
    "    # Visualizar a matriz de correlação\n",
    "    print(\"\\nExiste alguma correlação entre certas características (por exemplo, idade, IMC) e os custos médicos?\")\n",
    "    print(correlation_matrix)\n",
    "else:\n",
    "    print(\"O modelo selecionado não suporta o cálculo de importância das características.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a03c62-b587-404f-a8bd-5f6ae92ba516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validação cruzada para detecção de overfitting\n",
    "def overfitting_detection(model, X_train_scaled, y_train, X_test_scaled, y_test):\n",
    "    train_mse = -cross_val_score(model, X_train_scaled, y_train, cv=kfold, scoring='neg_mean_squared_error').mean()\n",
    "    test_mse = mean_squared_error(y_test, model.predict(X_test_scaled))\n",
    "    return train_mse, test_mse\n",
    "\n",
    "train_mse, test_mse = overfitting_detection(best_model, X_train_scaled, y_train, X_test_scaled, y_test)\n",
    "\n",
    "print(\"Erro Médio Quadrático (MSE) no conjunto de treinamento:\", round(train_mse,2))\n",
    "print(\"Erro Médio Quadrático (MSE) no conjunto de teste:\", round(test_mse,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85eb16b-00c1-4b47-8a9c-1f6381779783",
   "metadata": {},
   "source": [
    "**7. Entrega dos dados futuros**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3fbd6d-0cfe-4813-85ab-263f3df578b1",
   "metadata": {},
   "source": [
    "Nesta seção geramos um novo dataset de dados futuros seguindo as mesmas features de X_test. \n",
    "\n",
    "Aplicamos a padronização usando o scaler, fizemos previsões de encargos futuros usando o melhor modelo treinado, classificamos os grupos de risco e revertemos a codificação de rótulos.\n",
    "\n",
    "Além disso, calculamos a expectativa do plano de saúde, entregamos os planos estratégicos e salvamos estes insights em um arquivo CSV.\n",
    "\n",
    "No final exibimos gráficos destes insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23985e9b-b6cd-40ad-8768-a1a172cad14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Código comentado, mas mantido para estudos futuros\n",
    "# Copiando X_test para tratar as transformações feitas e usar abaixo para randomizar os dados futuros\n",
    "# X_test_aux = X_test.copy()\n",
    "\n",
    "# Inserir as colunas descartadas em X_test\n",
    "# for coluna in colunas_descartadas_treino.columns:\n",
    "#    X_test_aux.insert(loc=len(X_test_aux.columns), column=coluna, value=colunas_descartadas_treino[coluna])\n",
    "\n",
    "# print(X_test_aux.head(50))\n",
    "\n",
    "# Lista para armazenar as colunas que passaram por LabelEncoder\n",
    "# colunas_label_encoded = []\n",
    "\n",
    "# Verifica quais colunas passaram por LabelEncoder\n",
    "# for coluna in dados_originais.columns:\n",
    "#    if dados_originais[coluna].dtype == 'object' and X_test_aux[coluna].dtype == 'int64':\n",
    "#        colunas_label_encoded.append(coluna)\n",
    "\n",
    "# print(colunas_label_encoded)\n",
    "\n",
    "# Ajuste o LabelEncoder aos dados de treinamento original\n",
    "# label_encoder = LabelEncoder()\n",
    "# label_encoder.fit(dados_originais['Fumante'])\n",
    "\n",
    "# Revertendo a codificação de rótulos\n",
    "# fumante_aux = label_encoder.inverse_transform(X_test_aux['Fumante'])\n",
    "# X_test_aux.insert(X_test_aux.columns.get_loc('Fumante') + 1, 'Fumante2', fumante_aux)\n",
    "# print(X_test_aux.head(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9764f9-5560-4e6d-99a9-e8814bf3656f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variável necessária para geração dos dados futuros (mantivemos uma menor quantidade para poder ver melhor no gráfico visto posteriormente)\n",
    "novas_linhas_dados_futuros = 200\n",
    "\n",
    "# Criando um novo dataset, respeitando a quantidade de novas linhas indicadas, assim como seguindo as mesmas features do X_test\n",
    "dados_futuros = gerar_dados_futuros_com_limites(novas_linhas=novas_linhas_dados_futuros, x_test=X_test)\n",
    "\n",
    "# Aplicando a mesma transformação de padronização aos dados futuros\n",
    "dados_futuros_scaled = scaler.transform(dados_futuros)\n",
    "\n",
    "# Modelo treinado para fazer previsões dos encargos futuros\n",
    "encargos_futuros = prever_encargos_futuros(best_model, dados_futuros_scaled)\n",
    "\n",
    "# Grupos de indivíduos com diferentes níveis de risco\n",
    "grupos_risco = obter_grupo_de_risco(best_model, dados_futuros_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5651aad-ab93-4e5d-9119-62173d584776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajustando o LabelEncoder aos dados de treinamento original\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(dados_originais['Fumante'])\n",
    "\n",
    "# Revertendo a codificação de rótulos\n",
    "dados_futuros['Fumante'] = label_encoder.inverse_transform(dados_futuros['Fumante'])\n",
    "\n",
    "# Inserindo as colunas descartadas em X_test\n",
    "for coluna in colunas_descartadas_treino.columns:\n",
    "    dados_futuros.insert(loc=len(dados_futuros.columns), column=coluna, value=colunas_descartadas_treino[coluna])\n",
    "\n",
    "# Adicionando as novas colunas na planilha dados futuros\n",
    "dados_futuros['Encargos Reais'] = obter_encargo_por_coeficientes(dados_futuros, novas_linhas_dados_futuros)\n",
    "dados_futuros['Encargos Futuro'] = encargos_futuros\n",
    "dados_futuros['Grupos Risco'] = grupos_risco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b16f940-2768-45ed-a041-4aa7308100a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizando as previsões dos encargos para verificar a expectativa do orçamento do plano de saúde\n",
    "expectativa_plano_saude = expectativa_plano_saude(dados_futuros)\n",
    "\n",
    "# Utilizando as informações obtidas com o modelo para desenvolver planos estratégicos\n",
    "planos_estrategicos = planejamento_estrategico(best_model, dados_futuros_scaled, encargos_futuros)\n",
    "\n",
    "# Exibindo de forma tratado os dados na feature\n",
    "dados_futuros['Fumante'] = dados_futuros['Fumante'].fillna('Não informado')\n",
    "\n",
    "# Criando novas colunas na planilha dados futuros\n",
    "dados_futuros['Expectativa Plano de Saúde'] = expectativa_plano_saude\n",
    "dados_futuros['Planos estratégicos'] = planos_estrategicos\n",
    "\n",
    "# Salvando os dados randômicos futuros\n",
    "dados_futuros.to_csv(\"../planilhas/7_dados_futuros.csv\", index=False, encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda3adbb-21d1-4f0c-850f-9136f82c2904",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibindo os gráficos com as previsões futuras\n",
    "montar_graficos_dados_futuros(dados_futuros)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
